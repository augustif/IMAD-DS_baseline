{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# custom\n",
    "import model\n",
    "import utilities\n",
    "from datasets.dataset_IMADS import DatasetTrain, DatasetTest, DatasetFromNumpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINE = 'BrushlessMotor' # choose between BrushlessMotor and RoboticArm\n",
    "WINDOW_SIZE_MS = 100 # milliseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "PARAMS = {\n",
    "    'layer_dims': [2048, 2048, 2048, 16],\n",
    "    'lr': 0.0001,\n",
    "    'criterion': utilities.MSE,\n",
    "    'batch_size': 1024,\n",
    "    'num_epochs': 1000,\n",
    "    'patience': 3,\n",
    "    'normalisation': 'std_window', # ('std', 'min-max', 'std_window', or 'min-max_window')\n",
    "    'valid_size': 0.1,\n",
    "    'seed': 1995,\n",
    "    'device':device\n",
    "}\n",
    "\n",
    "# Set the seed for general torch operations\n",
    "torch.manual_seed(PARAMS['seed'])\n",
    "# Set the seed for MPS torch operations (ones that happen on the MPS Apple GPU)\n",
    "\n",
    "if device == 'mps':\n",
    "    torch.mps.manual_seed(PARAMS['seed'])\n",
    "elif device == 'cuda':\n",
    "    torch.cuda.manual_seed(PARAMS['seed'])\n",
    "elif device == 'cpu':\n",
    "    torch.manual_seed(PARAMS['seed'])\n",
    "else:\n",
    "    raise ValueError(f\"Wrong device value: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DatasetTrain(machine=MACHINE, window_size_ms=WINDOW_SIZE_MS, params=PARAMS)\n",
    "X_valid, y_valid = train_dataset.get_valid_dataset()\n",
    "valid_dataset = DatasetFromNumpy(X_valid, y_valid['anomaly_label'].to_list(), device, PARAMS['normalisation'])\n",
    "test_dataset = DatasetTest(machine=MACHINE, window_size_ms=WINDOW_SIZE_MS, params=PARAMS)\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset, batch_size=PARAMS['batch_size'], shuffle=True)\n",
    "valid_data_loader = DataLoader(\n",
    "    valid_dataset, batch_size=PARAMS['batch_size'], shuffle=False)\n",
    "test_data_loader = DataLoader(\n",
    "    test_dataset, batch_size=PARAMS['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the number of channels and window lengths for each sensor\\n\",\n",
    "NUM_CHANNELS = [x.shape[1] for x in train_dataset.X]\n",
    "WINDOW_LENGTHS = [x.shape[2] for x in train_dataset.X]\n",
    "SENSORS = train_dataset.sensor_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = model.AutoencoderFC(WINDOW_LENGTHS, NUM_CHANNELS, PARAMS, SENSORS)\n",
    "optimizer = torch.optim.Adam(baseline.parameters(), lr=PARAMS['lr'])\n",
    "baseline.fit(train_data_loader, valid_data_loader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_scores = baseline.test(test_data_loader, test_dataset.y, utilities.MSE, 'median')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show results table as in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = AUC_scores.copy()\n",
    "results.columns = ['S+T', 'Source', 'Target']\n",
    "new_order = [\n",
    "    'total_loss',\n",
    "    'f_ism330dhcx_acc',\n",
    "    's_ism330dhcx_acc',\n",
    "    'f_ism330dhcx_gyro',\n",
    "    's_ism330dhcx_gyro',\n",
    "    'f_imp23absu_mic',\n",
    "    's_imp23absu_mic']\n",
    "results = results.reindex(new_order)\n",
    "results.index = [\n",
    "    'Overall',\n",
    "    'F-acc',\n",
    "    'S-acc',\n",
    "    'F-gyr',\n",
    "    'S-gyr',\n",
    "    'F-mic',\n",
    "    'S-mic']\n",
    "results = results * 100\n",
    "results = results.round(2)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "MODEL_PATH = f'models/{MACHINE}'\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "\n",
    "torch.save(\n",
    "    baseline.state_dict(),\n",
    "    MODEL_PATH +\n",
    "    os.sep +\n",
    "    f'baseline_seed{PARAMS[\"seed\"]}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = f'results/{MACHINE}'\n",
    "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
    "results.to_csv(RESULTS_PATH + os.sep + 'AUC_scores.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
